/**
 * @file Template generator for AI Module files
 */

export interface AIModuleTemplateOptions {
  providers?: string[];
  defaultProvider?: string;
  defaultModel?: string;
}

/**
 * Generate a TypeScript file for a new AI module
 *
 * @param name - Name of the AI module
 * @param options - Template options
 * @returns Generated file content
 */
export function generateAIModuleTemplate(
  name: string,
  options: AIModuleTemplateOptions = {},
): string {
  const {
    providers = ['anthropic', 'openai'],
    defaultProvider = 'anthropic',
    defaultModel,
  } = options;

  const providersList = `['${providers.join("', '")}']`;
  const defaultModelCode = defaultModel
    ? `defaultModel: '${defaultModel}',`
    : `// defaultModel: 'claude-3-sonnet-20240229', // Uncomment and set your preferred model`;

  return `/**
 * @file ${name} - Custom AI module implementation
 *
 * This module extends BaseAIModule to provide AI-powered functionality.
 * Automatically generated by JBish-Kit CLI.
 *
 * HOW TO EXTEND THIS MODULE:
 * 1. Define your input and output types (replace 'any' below)
 * 2. Implement the process() method with your AI logic
 * 3. Override makeAIRequest() to integrate with actual AI providers
 * 4. Build effective prompts for your use case
 * 5. Parse and structure AI responses appropriately
 *
 * @example
 * \`\`\`typescript
 * import { ${name} } from '@repo/core/ai-modules/${name}';
 *
 * const module = new ${name}();
 * const result = await module.run({ /* your input */ });
 *
 * if (result.success) {
 *   console.log('Result:', result.data);
 *   console.log('AI calls made:', result.metadata?.aiCalls);
 *   console.log('Tokens used:', result.metadata?.totalTokens);
 * } else {
 *   console.error('Error:', result.error);
 * }
 * \`\`\`
 */

import {
  BaseAIModule,
  AIModuleConfig,
  AICallOptions,
  AIResponse,
} from './BaseAIModule';

/**
 * Input type for ${name}
 *
 * TODO: Define the structure of data this module accepts
 */
export interface ${name}Input {
  // Add your input fields here
  // Example:
  // text: string;
  // options?: {
  //   style: 'formal' | 'casual';
  //   maxLength?: number;
  // };
}

/**
 * Output type for ${name}
 *
 * TODO: Define the structure of data this module returns
 */
export interface ${name}Output {
  // Add your output fields here
  // Example:
  // result: string;
  // confidence: number;
  // metadata?: {
  //   tokensUsed: number;
  //   model: string;
  // };
}

/**
 * ${name} - [Add brief description here]
 *
 * [Add detailed description of what this AI module does and how it uses AI]
 *
 * Supported Providers:
${providers.map((p) => ` * - ${p}`).join('\n')}
 *
 * Key Features:
 * - [Feature 1]
 * - [Feature 2]
 * - [Feature 3]
 *
 * Use Cases:
 * - [Use case 1]
 * - [Use case 2]
 */
export class ${name} extends BaseAIModule<${name}Input, ${name}Output> {
  /**
   * Create a new ${name} instance
   */
  constructor() {
    super('${name}', {
      description: 'TODO: Add a brief description of what this AI module does',
      version: '1.0.0',
      providers: ${providersList},
      defaultProvider: '${defaultProvider}',
      ${defaultModelCode}
      capabilities: [
        // Add module capabilities here
        // Example: 'text-generation', 'analysis', 'summarization'
      ],
    });
  }

  /**
   * Initialize the module
   *
   * This hook is called once before the first processing.
   * Override this to set up any resources or validate configuration.
   *
   * @example
   * \`\`\`typescript
   * protected async onInitialize(): Promise<void> {
   *   // Validate API keys
   *   if (!process.env.ANTHROPIC_API_KEY) {
   *     throw new Error('ANTHROPIC_API_KEY is required');
   *   }
   *   
   *   // Initialize any caches or resources
   *   this.cache = new Map();
   * }
   * \`\`\`
   */
  protected async onInitialize(): Promise<void> {
    // TODO: Add your initialization logic here
    // Examples:
    // - Validate API keys are set
    // - Initialize caches
    // - Set up rate limiting
    // - Load prompt templates
  }

  /**
   * Process input with AI
   *
   * This is where you implement the main AI-powered functionality.
   * Use this.callAI() to interact with AI providers.
   *
   * Tips:
   * - Build clear, specific prompts
   * - Include examples in prompts when helpful
   * - Use appropriate temperature settings
   * - Parse AI responses carefully
   * - Handle errors gracefully
   *
   * @param input - The input data for this module
   * @returns The processed output
   *
   * @example
   * \`\`\`typescript
   * protected async process(input: ${name}Input): Promise<${name}Output> {
   *   // Build the prompt
   *   const prompt = this.buildPrompt(input);
   *   
   *   // Call AI
   *   const response = await this.callAI({
   *     prompt,
   *     provider: this.config.defaultProvider!,
   *     model: this.config.defaultModel || 'claude-3-sonnet-20240229',
   *     temperature: 0.7,
   *     maxTokens: 1000
   *   });
   *   
   *   // Parse and return result
   *   return this.parseResponse(response.content);
   * }
   * \`\`\`
   */
  protected async process(input: ${name}Input): Promise<${name}Output> {
    // TODO: Implement your AI processing logic here

    // Step 1: Build the prompt
    const prompt = this.buildPrompt(input);

    // Step 2: Call the AI provider
    const response = await this.callAI({
      prompt,
      provider: this.config.defaultProvider!,
      model: this.config.defaultModel || 'claude-3-sonnet-20240229',
      temperature: 0.7, // Adjust based on your needs (0 = deterministic, 1 = creative)
      maxTokens: 1000, // Adjust based on expected output length
      systemPrompt: this.getSystemPrompt(),
    });

    // Step 3: Parse and structure the response
    const result = this.parseResponse(response.content);

    return result;
  }

  /**
   * Make the actual AI API request
   *
   * Override this method to integrate with real AI providers.
   * The base class will call this method when you use this.callAI()
   *
   * @param options - Options for the AI call
   * @returns AI response
   *
   * @example
   * \`\`\`typescript
   * protected async makeAIRequest(options: AICallOptions): Promise<AIResponse> {
   *   if (options.provider === 'anthropic') {
   *     return this.callAnthropic(options);
   *   } else if (options.provider === 'openai') {
   *     return this.callOpenAI(options);
   *   }
   *   throw new Error(\`Unsupported provider: \${options.provider}\`);
   * }
   * \`\`\`
   */
  protected async makeAIRequest(
    options: AICallOptions,
  ): Promise<AIResponse> {
    // TODO: Implement actual AI provider integration
    
    // For now, this throws an error. You need to implement the actual
    // API calls to your AI provider(s).
    
    if (options.provider === 'anthropic') {
      return this.callAnthropic(options);
    } else if (options.provider === 'openai') {
      return this.callOpenAI(options);
    } else if (options.provider === 'cloudflare') {
      return this.callCloudflareAI(options);
    }

    throw new Error(
      \`AI provider "\${options.provider}" not implemented. Add integration in makeAIRequest().\`,
    );
  }

  /**
   * Clean up module resources
   *
   * This hook is called when the module is being shut down.
   *
   * @example
   * \`\`\`typescript
   * protected async onCleanup(): Promise<void> {
   *   // Clear caches
   *   this.cache?.clear();
   *   
   *   // Close any open connections
   *   await this.apiClient?.disconnect();
   * }
   * \`\`\`
   */
  protected async onCleanup(): Promise<void> {
    // TODO: Add your cleanup logic here
  }

  // ============================================================================
  // HELPER METHODS
  // ============================================================================

  /**
   * Build a prompt from the input
   *
   * @param input - Input data
   * @returns Formatted prompt string
   */
  private buildPrompt(input: ${name}Input): string {
    // TODO: Implement prompt building logic
    
    // Example using template:
    // return this.formatPrompt(
    //   \`You are an expert at {{task}}.
    //
    //   Input: {{input}}
    //
    //   Please provide {{output_type}}.\`,
    //   {
    //     task: 'your task description',
    //     input: JSON.stringify(input),
    //     output_type: 'the expected output format'
    //   }
    // );

    // Placeholder - replace with actual implementation
    return \`Process this input: \${JSON.stringify(input)}\`;
  }

  /**
   * Get the system prompt
   *
   * The system prompt provides context and instructions for the AI.
   *
   * @returns System prompt string
   */
  private getSystemPrompt(): string {
    // TODO: Define your system prompt
    return \`You are a helpful AI assistant specialized in [your domain].
Your responses should be [characteristics: accurate, concise, detailed, etc.].\`;
  }

  /**
   * Parse the AI response into structured output
   *
   * @param content - Raw AI response content
   * @returns Structured output
   */
  private parseResponse(content: string): ${name}Output {
    // TODO: Implement response parsing logic
    
    // Example for JSON responses:
    // try {
    //   // Extract JSON from markdown code blocks if present
    //   const jsonMatch = content.match(/\`\`\`json\\n([\\s\\S]*?)\\n\`\`\`/) ||
    //                    content.match(/\\[[\\s\\S]*\\]|\\{[\\s\\S]*\\}/);
    //   if (jsonMatch) {
    //     return JSON.parse(jsonMatch[1] || jsonMatch[0]);
    //   }
    // } catch (error) {
    //   throw new Error(\`Failed to parse AI response: \${error}\`);
    // }

    // Placeholder - replace with actual implementation
    throw new Error('parseResponse() not implemented yet');
  }

  // ============================================================================
  // AI PROVIDER INTEGRATIONS
  // ============================================================================

  /**
   * Call Anthropic's Claude API
   *
   * @param options - AI call options
   * @returns AI response
   */
  private async callAnthropic(options: AICallOptions): Promise<AIResponse> {
    // TODO: Implement Anthropic integration
    
    // Example implementation:
    // const response = await fetch('https://api.anthropic.com/v1/messages', {
    //   method: 'POST',
    //   headers: {
    //     'x-api-key': process.env.ANTHROPIC_API_KEY!,
    //     'anthropic-version': '2023-06-01',
    //     'content-type': 'application/json',
    //   },
    //   body: JSON.stringify({
    //     model: options.model,
    //     max_tokens: options.maxTokens || 1024,
    //     temperature: options.temperature || 0.7,
    //     system: options.systemPrompt,
    //     messages: [{ role: 'user', content: options.prompt }],
    //   }),
    // });
    //
    // const data = await response.json();
    //
    // return {
    //   content: data.content[0].text,
    //   provider: 'anthropic',
    //   model: options.model,
    //   metadata: {
    //     tokens: data.usage.input_tokens + data.usage.output_tokens,
    //     finishReason: data.stop_reason,
    //   },
    // };

    throw new Error('Anthropic integration not implemented');
  }

  /**
   * Call OpenAI's API
   *
   * @param options - AI call options
   * @returns AI response
   */
  private async callOpenAI(options: AICallOptions): Promise<AIResponse> {
    // TODO: Implement OpenAI integration
    
    // Example implementation:
    // const response = await fetch('https://api.openai.com/v1/chat/completions', {
    //   method: 'POST',
    //   headers: {
    //     'Authorization': \`Bearer \${process.env.OPENAI_API_KEY}\`,
    //     'Content-Type': 'application/json',
    //   },
    //   body: JSON.stringify({
    //     model: options.model,
    //     messages: [
    //       { role: 'system', content: options.systemPrompt },
    //       { role: 'user', content: options.prompt }
    //     ],
    //     temperature: options.temperature || 0.7,
    //     max_tokens: options.maxTokens || 1024,
    //   }),
    // });
    //
    // const data = await response.json();
    //
    // return {
    //   content: data.choices[0].message.content,
    //   provider: 'openai',
    //   model: options.model,
    //   metadata: {
    //     tokens: data.usage.total_tokens,
    //     finishReason: data.choices[0].finish_reason,
    //   },
    // };

    throw new Error('OpenAI integration not implemented');
  }

  /**
   * Call Cloudflare Workers AI
   *
   * @param options - AI call options
   * @returns AI response
   */
  private async callCloudflareAI(options: AICallOptions): Promise<AIResponse> {
    // TODO: Implement Cloudflare AI integration
    
    // Example for use in Cloudflare Workers:
    // const response = await env.AI.run(options.model, {
    //   prompt: options.prompt,
    //   max_tokens: options.maxTokens || 1024,
    // });
    //
    // return {
    //   content: response.response,
    //   provider: 'cloudflare',
    //   model: options.model,
    //   metadata: {
    //     tokens: response.tokens_used,
    //   },
    // };

    throw new Error('Cloudflare AI integration not implemented');
  }
}

// ============================================================================
// USAGE EXAMPLES
// ============================================================================

/**
 * Example 1: Basic usage
 *
 * \`\`\`typescript
 * const module = new ${name}();
 * const result = await module.run({
 *   // your input data
 * });
 *
 * if (result.success) {
 *   console.log('Result:', result.data);
 *   console.log('Tokens used:', result.metadata?.totalTokens);
 * } else {
 *   console.error('Failed:', result.error);
 * }
 * \`\`\`
 */

/**
 * Example 2: With statistics tracking
 *
 * \`\`\`typescript
 * const module = new ${name}();
 *
 * await module.run(input1);
 * await module.run(input2);
 * await module.run(input3);
 *
 * const stats = module.getStats();
 * console.log('Total AI calls:', stats.totalCalls);
 * console.log('Total tokens:', stats.totalTokens);
 * console.log('Success rate:', stats.successfulCalls / stats.totalCalls);
 * \`\`\`
 */

/**
 * Example 3: In an API endpoint
 *
 * \`\`\`typescript
 * export default {
 *   async fetch(request: Request): Promise<Response> {
 *     const input = await request.json();
 *     
 *     const module = new ${name}();
 *     const result = await module.run(input);
 *     
 *     if (!result.success) {
 *       return Response.json({ error: result.error }, { status: 500 });
 *     }
 *     
 *     return Response.json({
 *       data: result.data,
 *       metadata: result.metadata
 *     });
 *   }
 * };
 * \`\`\`
 */
`;
}
